#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆå¤æ‚ä»»åŠ¡åˆ†è§£Agent
å…·å¤‡æ™ºèƒ½æ€»ç»“åˆ†æèƒ½åŠ›ï¼Œä½¿ç”¨LLMè¿›è¡Œæ·±åº¦åˆ†æå’Œæ¨ç†
"""

from academic_chat import AcademicChatAssistant
from academic_agent.llm import get_llm_adapter
from academic_agent.config import load_config
import re
from typing import List, Dict, Any


class EnhancedComplexTaskAgent:
    """å¢å¼ºç‰ˆå¤æ‚ä»»åŠ¡åˆ†è§£Agentï¼Œå…·å¤‡æ™ºèƒ½æ€»ç»“åˆ†æèƒ½åŠ›"""
    
    def __init__(self):
        """åˆå§‹åŒ–Agent"""
        self.assistant = AcademicChatAssistant()
        self.task_history = []
        
        # åˆå§‹åŒ–LLMç”¨äºæ€»ç»“åˆ†æ
        config = load_config()
        llm_config = config.get("llm", {}).get("zhipu", {})
        
        # ä½¿ç”¨ä¸ academic_chat.py ç›¸åŒçš„æ–¹å¼è·å–LLMé€‚é…å™¨
        self.llm_adapter = get_llm_adapter("zhipu", {
            "api_key": llm_config.get("api_key"),
            "model_name": llm_config.get("model", "qwen3-max"),
            "base_url": llm_config.get("base_url"),
            "temperature": 0.7,
            "max_tokens": 3000
        })
        
        print("ğŸ¤– å¢å¼ºç‰ˆå¤æ‚ä»»åŠ¡åˆ†è§£Agentå·²å¯åŠ¨ï¼")
        print("ğŸ’¡ å…·å¤‡æ™ºèƒ½æ€»ç»“åˆ†æèƒ½åŠ›")
        print("   - LLMé©±åŠ¨çš„æ·±åº¦åˆ†æ")
        print("   - å¤šæºä¿¡æ¯æ•´åˆ")
        print("   - æ™ºèƒ½ç­”æ¡ˆç”Ÿæˆ")
        print("   - ç½®ä¿¡åº¦è¯„ä¼°")
        print("\nè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º\n")
    
    def analyze_complexity(self, question: str) -> Dict[str, Any]:
        """
        åˆ†æé—®é¢˜å¤æ‚åº¦
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            å¤æ‚åº¦åˆ†æç»“æœ
        """
        question_lower = question.lower()
        
        features = {
            'has_multiple_entities': False,
            'has_time_range': False,
            'has_geographic_scope': False,
            'has_causal_chain': False,
            'has_comparison': False,
            'has_specific_year': False,
            'requires_synthesis': False
        }
        
        entities = re.findall(r'[\u4e00-\u9fff]{2,}|[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*', question)
        if len(entities) > 3:
            features['has_multiple_entities'] = True
        
        if re.search(r'(20ä¸–çºª|ä¸ŠåŠå¶|ä¸‹åŠå¶|ç‹¬ç«‹|è¡°è½|å†·æˆ˜|ä».*åˆ°.*)', question):
            features['has_time_range'] = True
        
        if re.search(r'(æ¬§æ´²|å—äºš|ä¸œäºš|å²›å›½|å¤§é™†|æµ·å³¡|é€šé“)', question):
            features['has_geographic_scope'] = True
        
        if re.search(r'(å› ä¸º|å¯¼è‡´|ç”±äº|æ‰€ä»¥|ä»è€Œ|è¿›è€Œ)', question):
            features['has_causal_chain'] = True
        
        if re.search(r'(å¯¹æ¯”|æ¯”è¾ƒ|åŒºåˆ«|å·®å¼‚|ç›¸åŒ)', question):
            features['has_comparison'] = True
        
        if re.search(r'(å…¶ä¸­ä¸€å¹´|åŒå¹´|å“ªä¸€å¹´|å“ªå¹´)', question):
            features['has_specific_year'] = True
        
        if re.search(r'(è¯·é—®|ç­”æ¡ˆæ˜¯|ç›´æ¥å›ç­”|ç»“è®º)', question):
            features['requires_synthesis'] = True
        
        complexity_score = sum(features.values())
        
        return {
            'features': features,
            'complexity_score': complexity_score,
            'complexity_level': self._get_complexity_level(complexity_score)
        }
    
    def _get_complexity_level(self, score: int) -> str:
        """è·å–å¤æ‚åº¦ç­‰çº§"""
        if score <= 2:
            return "ç®€å•"
        elif score <= 4:
            return "ä¸­ç­‰"
        elif score <= 6:
            return "å¤æ‚"
        else:
            return "éå¸¸å¤æ‚"
    
    def decompose_task(self, question: str) -> List[Dict[str, Any]]:
        """
        åˆ†è§£å¤æ‚ä»»åŠ¡ä¸ºå¤šä¸ªå­ä»»åŠ¡
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            å­ä»»åŠ¡åˆ—è¡¨
        """
        tasks = []
        analysis = self.analyze_complexity(question)
        
        print(f"\n{'='*80}")
        print("ğŸ“Š é—®é¢˜å¤æ‚åº¦åˆ†æ")
        print(f"{'='*80}")
        print(f"å¤æ‚åº¦ç­‰çº§: {analysis['complexity_level']}")
        print(f"å¤æ‚åº¦å¾—åˆ†: {analysis['complexity_score']}")
        print(f"\né—®é¢˜ç‰¹å¾:")
        for feature, value in analysis['features'].items():
            if value:
                print(f"  âœ“ {feature}")
        
        if analysis['features']['has_specific_year'] and analysis['features']['requires_synthesis']:
            tasks.extend(self._create_year_finding_tasks(question))
        elif analysis['features']['has_multiple_entities'] and analysis['features']['has_time_range']:
            tasks.extend(self._create_multi_entity_tasks(question))
        elif analysis['features']['has_comparison']:
            tasks.extend(self._create_comparison_tasks(question))
        else:
            tasks.extend(self._create_keyword_search_tasks(question))
        
        return tasks
    
    def _create_year_finding_tasks(self, question: str) -> List[Dict[str, Any]]:
        """åˆ›å»ºå¹´ä»½æŸ¥æ‰¾å­ä»»åŠ¡"""
        tasks = []
        
        if re.search(r'(ç§‘å­¦å®¶|å­¦è€…|ä¸“å®¶)', question):
            tasks.append({
                'type': 'search',
                'description': 'æœç´¢ç›¸å…³ç§‘å­¦å®¶/å­¦è€…çš„æ–‡çŒ®',
                'keywords': ['scientist', 'scholar', 'return'],
                'priority': 'high'
            })
        
        if re.search(r'(ç›‘ç¦|æ‹˜ç•™|è½¯ç¦)', question):
            tasks.append({
                'type': 'search',
                'description': 'æœç´¢ç›‘ç¦/æ‹˜ç•™ç›¸å…³çš„å­¦æœ¯æ–‡çŒ®',
                'keywords': ['imprisonment', 'detention', 'house arrest'],
                'priority': 'high'
            })
        
        if re.search(r'(æ¡£æ¡ˆ|archives|document)', question):
            tasks.append({
                'type': 'search',
                'description': 'æœç´¢æ¡£æ¡ˆ/æ–‡çŒ®ç›¸å…³çš„å­¦æœ¯ç ”ç©¶',
                'keywords': ['archives', 'document', 'records'],
                'priority': 'medium'
            })
        
        if re.search(r'(é¢å¸ƒ|å†³å®š|law|regulation)', question):
            tasks.append({
                'type': 'search',
                'description': 'æœç´¢æ³•å¾‹/æ³•è§„ç›¸å…³çš„æ–‡çŒ®',
                'keywords': ['law', 'regulation', 'policy'],
                'priority': 'medium'
            })
        
        return tasks
    
    def _create_multi_entity_tasks(self, question: str) -> List[Dict[str, Any]]:
        """åˆ›å»ºå¤šå®ä½“æœç´¢å­ä»»åŠ¡"""
        tasks = []
        
        geographic_entities = re.findall(r'(æ¬§æ´²|å—äºš|ä¸œäºš|å²›å›½|å¤§é™†|æµ·å³¡|é€šé“)', question)
        for entity in geographic_entities:
            tasks.append({
                'type': 'search',
                'description': f'æœç´¢å…³äº{entity}çš„å­¦æœ¯æ–‡çŒ®',
                'keywords': [entity],
                'priority': 'medium'
            })
        
        if re.search(r'(20ä¸–çºª|ä¸ŠåŠå¶|ä¸‹åŠå¶)', question):
            tasks.append({
                'type': 'search',
                'description': 'æœç´¢20ä¸–çºªä¸ŠåŠå¶çš„å†å²æ–‡çŒ®',
                'keywords': ['20th century', 'early 20th century'],
                'priority': 'medium'
            })
        
        return tasks
    
    def _create_comparison_tasks(self, question: str) -> List[Dict[str, Any]]:
        """åˆ›å»ºå¯¹æ¯”åˆ†æå­ä»»åŠ¡"""
        tasks = []
        
        comparison_objects = re.findall(r'[\u4e00-\u9fff]{2,}|[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*', question)
        
        for obj in comparison_objects[:2]:
            tasks.append({
                'type': 'search',
                'description': f'æœç´¢å…³äº{obj}çš„å­¦æœ¯æ–‡çŒ®',
                'keywords': [obj],
                'priority': 'high'
            })
        
        tasks.append({
            'type': 'llm_compare',
            'description': 'ä½¿ç”¨LLMè¿›è¡Œå¯¹æ¯”åˆ†æ',
            'keywords': comparison_objects[:2],
            'priority': 'high'
        })
        
        return tasks
    
    def _create_keyword_search_tasks(self, question: str) -> List[Dict[str, Any]]:
        """åˆ›å»ºå…³é”®è¯æœç´¢å­ä»»åŠ¡"""
        tasks = []
        
        keywords = self.assistant.extract_keywords(question)
        
        for keyword in keywords[:3]:
            tasks.append({
                'type': 'search',
                'description': f'æœç´¢å…³äº"{keyword}"çš„å­¦æœ¯æ–‡çŒ®',
                'keywords': [keyword],
                'priority': 'medium'
            })
        
        return tasks
    
    def execute_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•ä¸ªå­ä»»åŠ¡
        
        Args:
            task: å­ä»»åŠ¡
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        print(f"\n{'â”€'*80}")
        print(f"ğŸ¯ æ‰§è¡Œä»»åŠ¡: {task['description']}")
        print(f"   ç±»å‹: {task['type']}")
        print(f"   ä¼˜å…ˆçº§: {task['priority']}")
        print(f"{'â”€'*80}")
        
        result = {
            'task': task,
            'status': 'pending',
            'data': None,
            'error': None,
            'papers': []
        }
        
        try:
            if task['type'] == 'search':
                for keyword in task['keywords']:
                    search_question = f"æœç´¢å…³äº{keyword}çš„å­¦æœ¯æ–‡çŒ®"
                    
                    papers = self._search_papers(keyword)
                    result['papers'] = papers
                    result['keyword'] = keyword
                    result['found'] = len(papers) > 0
                    result['status'] = 'completed'
                    return result
            
            elif task['type'] == 'llm_compare':
                compare_question = f"å¯¹æ¯”{task['keywords'][0]}å’Œ{task['keywords'][1]}"
                self.assistant.ask(compare_question)
                result['status'] = 'completed'
                return result
            
            else:
                result['status'] = 'skipped'
                result['error'] = f"æœªçŸ¥ä»»åŠ¡ç±»å‹: {task['type']}"
                return result
                
        except Exception as e:
            result['status'] = 'failed'
            result['error'] = str(e)
            return result
    
    def _search_papers(self, keyword: str) -> List[Dict[str, Any]]:
        """æœç´¢è®ºæ–‡å¹¶è¿”å›ç»“æœ"""
        try:
            papers = self.assistant.service.basic_query.handle({
                "action": "search_papers",
                "keywords": keyword,
                "limit": 5
            })
            
            if papers.get("code") == 200:
                return papers.get("data", [])
            return []
        except Exception as e:
            print(f"æœç´¢å¤±è´¥: {e}")
            return []
    
    def synthesize_results(self, tasks: List[Dict[str, Any]], question: str) -> str:
        """
        ä½¿ç”¨LLMæ™ºèƒ½ç»¼åˆæ‰€æœ‰å­ä»»åŠ¡çš„ç»“æœ
        
        Args:
            tasks: å­ä»»åŠ¡åˆ—è¡¨
            question: åŸå§‹é—®é¢˜
            
        Returns:
            ç»¼åˆç»“æœ
        """
        print(f"\n{'='*80}")
        print("ğŸ“Š æ™ºèƒ½ç»¼åˆåˆ†æ")
        print(f"{'='*80}\n")
        
        completed_tasks = [t for t in tasks if t['status'] == 'completed']
        failed_tasks = [t for t in tasks if t['status'] == 'failed']
        
        # æ”¶é›†æ‰€æœ‰æœç´¢åˆ°çš„è®ºæ–‡ä¿¡æ¯
        all_papers = []
        for task in completed_tasks:
            if 'papers' in task:
                all_papers.extend(task['papers'])
        
        # ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½åˆ†æ
        llm_analysis = self._llm_synthesize(question, completed_tasks, all_papers)
        
        synthesis = f"""
## é—®é¢˜åˆ†æ

åŸå§‹é—®é¢˜: {question}

## ä»»åŠ¡æ‰§è¡Œæƒ…å†µ

âœ… å·²å®Œæˆä»»åŠ¡: {len(completed_tasks)}/{len(tasks)}
âŒ å¤±è´¥ä»»åŠ¡: {len(failed_tasks)}/{len(tasks)}
ğŸ“š æœç´¢åˆ°è®ºæ–‡: {len(all_papers)} ç¯‡

## æ™ºèƒ½ç»¼åˆåˆ†æ

{llm_analysis}

## æœç´¢åˆ°çš„å…³é”®æ–‡çŒ®

"""
        
        # æ·»åŠ å‰5ç¯‡è®ºæ–‡çš„ä¿¡æ¯
        for i, paper in enumerate(all_papers[:5], 1):
            synthesis += f"{i}. {paper.get('title', 'N/A')}\n"
            synthesis += f"   ä½œè€…: {', '.join([a.get('name', 'Unknown') if isinstance(a, dict) else str(a) for a in paper.get('authors', [])[:3]])}\n"
            synthesis += f"   å¹´ä»½: {paper.get('publication_year', 'N/A')}\n"
            synthesis += f"   æœŸåˆŠ: {paper.get('venue', 'N/A')}\n\n"
        
        synthesis += """
## å»ºè®®

1. æŸ¥çœ‹æ‰€æœ‰æœç´¢ç»“æœçš„è¯¦ç»†ä¿¡æ¯ï¼Œç‰¹åˆ«å…³æ³¨å¹´ä»½ä¿¡æ¯
2. ä½¿ç”¨LLMå¯¹å…³é”®æ–‡çŒ®è¿›è¡Œæ·±å…¥åˆ†æ
3. äº¤å‰éªŒè¯ä¸åŒæ¥æºçš„ä¿¡æ¯
4. å¦‚éœ€æ›´ç²¾ç¡®çš„ç­”æ¡ˆï¼Œå»ºè®®æŸ¥é˜…åŸå§‹æ¡£æ¡ˆæˆ–å†å²æ–‡çŒ®

"""
        
        return synthesis
    
    def _llm_synthesize(self, question: str, tasks: List[Dict[str, Any]], papers: List[Dict[str, Any]]) -> str:
        """
        ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½ç»¼åˆåˆ†æ
        
        Args:
            question: åŸå§‹é—®é¢˜
            tasks: å­ä»»åŠ¡åˆ—è¡¨
            papers: æœç´¢åˆ°çš„è®ºæ–‡
            
        Returns:
            LLMåˆ†æç»“æœ
        """
        # æ„å»ºè®ºæ–‡æ‘˜è¦
        papers_summary = ""
        for i, paper in enumerate(papers[:10], 1):
            authors = ', '.join([a.get('name', 'Unknown') if isinstance(a, dict) else str(a) for a in paper.get('authors', [])[:3]])
            papers_summary += f"\nè®ºæ–‡{i}: {paper.get('title', 'N/A')}\n"
            papers_summary += f"ä½œè€…: {authors}\n"
            papers_summary += f"å¹´ä»½: {paper.get('publication_year', 'N/A')}\n"
            papers_summary += f"æ‘˜è¦: {(paper.get('abstract') or 'N/A')[:200]}...\n"
        
        # æ„å»ºLLMæç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªå­¦æœ¯ç ”ç©¶åŠ©æ‰‹ï¼Œéœ€è¦æ ¹æ®æœç´¢åˆ°çš„å­¦æœ¯æ–‡çŒ®å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜:
{question}

æœç´¢åˆ°çš„å­¦æœ¯æ–‡çŒ®:
{papers_summary}

è¯·åŸºäºä»¥ä¸Šæ–‡çŒ®ä¿¡æ¯ï¼Œè¿›è¡Œä»¥ä¸‹åˆ†æ:

1. **å…³é”®ä¿¡æ¯æå–**: ä»æ–‡çŒ®ä¸­æå–ä¸é—®é¢˜ç›¸å…³çš„å…³é”®ä¿¡æ¯ï¼ŒåŒ…æ‹¬äººç‰©ã€äº‹ä»¶ã€æ—¶é—´ã€åœ°ç‚¹ç­‰
2. **é€»è¾‘æ¨ç†**: åŸºäºæå–çš„ä¿¡æ¯ï¼Œè¿›è¡Œé€»è¾‘æ¨ç†ï¼Œæ‰¾å‡ºé—®é¢˜çš„ç­”æ¡ˆ
3. **ç­”æ¡ˆç”Ÿæˆ**: å¦‚æœé—®é¢˜è¦æ±‚ç›´æ¥å›ç­”ï¼ˆå¦‚å¹´ä»½ã€æ•°å­—ç­‰ï¼‰ï¼Œè¯·ç»™å‡ºæ˜ç¡®çš„ç­”æ¡ˆ
4. **ç½®ä¿¡åº¦è¯„ä¼°**: è¯„ä¼°ä½ çš„ç­”æ¡ˆçš„å¯ä¿¡åº¦ï¼ˆé«˜/ä¸­/ä½ï¼‰ï¼Œå¹¶è¯´æ˜ç†ç”±
5. **ä¿¡æ¯ç¼ºå£**: æŒ‡å‡ºæœç´¢ç»“æœä¸­ç¼ºå¤±çš„å…³é”®ä¿¡æ¯ï¼Œä»¥åŠè¿™äº›ä¿¡æ¯å¦‚ä½•å½±å“ç­”æ¡ˆçš„å‡†ç¡®æ€§

è¯·ä»¥ç»“æ„åŒ–çš„æ–¹å¼è¾“å‡ºä½ çš„åˆ†æç»“æœã€‚

åˆ†æç»“æœ:"""
        
        try:
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯ç ”ç©¶åŠ©æ‰‹ï¼Œæ“…é•¿ä»å­¦æœ¯æ–‡çŒ®ä¸­æå–ä¿¡æ¯å¹¶è¿›è¡Œé€»è¾‘æ¨ç†ã€‚"},
                {"role": "user", "content": prompt}
            ]
            
            result = self.llm_adapter.chat(messages)
            return result.get("content", "LLMåˆ†æå¤±è´¥")
        except Exception as e:
            return f"LLMåˆ†æå¤±è´¥: {str(e)}"
    
    def process_complex_question(self, question: str):
        """
        å¤„ç†å¤æ‚é—®é¢˜
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
        """
        self.task_history.append({
            'question': question,
            'timestamp': self._get_timestamp()
        })
        
        tasks = self.decompose_task(question)
        
        print(f"\n{'='*80}")
        print(f"ğŸ“‹ å·²åˆ†è§£ä¸º {len(tasks)} ä¸ªå­ä»»åŠ¡")
        print(f"{'='*80}\n")
        
        for i, task in enumerate(tasks, 1):
            print(f"{i}. {task['description']}")
            print(f"   ä¼˜å…ˆçº§: {task['priority']}")
        
        results = []
        for task in tasks:
            result = self.execute_task(task)
            results.append(result)
        
        synthesis = self.synthesize_results(results, question)
        
        print(synthesis)
        
        return synthesis
    
    def _get_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    def run(self):
        """è¿è¡Œäº¤äº’å¾ªç¯"""
        while True:
            try:
                question = input("\nğŸ’¬ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()
                
                if not question:
                    continue
                
                if question.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                    print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨å¢å¼ºç‰ˆå¤æ‚ä»»åŠ¡åˆ†è§£Agentï¼Œå†è§ï¼")
                    break
                
                self.process_complex_question(question)
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨å¢å¼ºç‰ˆå¤æ‚ä»»åŠ¡åˆ†è§£Agentï¼Œå†è§ï¼")
                break
            except Exception as e:
                print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•°"""
    agent = EnhancedComplexTaskAgent()
    agent.run()


if __name__ == "__main__":
    main()
