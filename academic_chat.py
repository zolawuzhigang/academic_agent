#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¯¹è¯å¼å­¦æœ¯åŠ©æ‰‹
"""

from academic_agent.services import LocalAcademicService
from academic_agent.llm import get_llm_adapter
from academic_agent.qa import LLMEnhancedResearchModule
from academic_agent.config import load_config
import re


class AcademicChatAssistant:
    """å­¦æœ¯å¯¹è¯åŠ©æ‰‹"""
    
    def __init__(self):
        """åˆå§‹åŒ–åŠ©æ‰‹"""
        # åŠ è½½é…ç½®
        config = load_config()
        llm_config = config.get("llm", {}).get("zhipu", {})
        
        # åˆå§‹åŒ–æœåŠ¡
        self.service = LocalAcademicService(adapter_name="openalex")
        
        # åˆå§‹åŒ–LLM
        self.llm_adapter = get_llm_adapter("zhipu", {
            "api_key": llm_config.get("api_key"),
            "model_name": llm_config.get("model", "qwen3-max"),
            "base_url": llm_config.get("base_url"),
            "temperature": llm_config.get("temperature", 0.7),
            "max_tokens": llm_config.get("max_tokens", 2000)
        })
        
        # åˆå§‹åŒ–LLMå¢å¼ºæ¨¡å—
        self.llm_module = LLMEnhancedResearchModule(
            adapter=self.service.adapter,
            llm_adapter=self.llm_adapter
        )
        
        print("ğŸ“ å­¦æœ¯åŠ©æ‰‹å·²å¯åŠ¨ï¼")
        print("ğŸ’¡ æ‚¨å¯ä»¥ç›´æ¥ç”¨ä¸­æ–‡æˆ–è‹±æ–‡æé—®ï¼Œä¾‹å¦‚ï¼š")
        print("   - 2024å¹´æœºå™¨å­¦ä¹ é¢†åŸŸæœ‰å“ªäº›é‡è¦è®ºæ–‡ï¼Ÿ")
        print("   - æ€»ç»“ä¸€ä¸‹Attention Is All You Needè¿™ç¯‡è®ºæ–‡")
        print("   - æ·±åº¦å­¦ä¹ é¢†åŸŸçš„ç ”ç©¶è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ")
        print("   - GPT-4æœ‰å“ªäº›åº”ç”¨åœºæ™¯ï¼Ÿ")
        print("   - æœç´¢å…³äºtransformerçš„è®ºæ–‡")
        print("   - æŸ¥è¯¢è®ºæ–‡W2626778328çš„è¯¦ç»†ä¿¡æ¯")
        print("\nè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º\n")
    
    def understand_question(self, question):
        """
        ç†è§£ç”¨æˆ·é—®é¢˜å¹¶ç¡®å®šæ“ä½œç±»å‹
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            æ“ä½œç±»å‹å’Œå‚æ•°
        """
        question_lower = question.lower()
        
        # ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦åŒ…å«è®ºæ–‡ID
        if re.search(r'W\d+', question):
            # å¦‚æœåŒ…å«è®ºæ–‡IDï¼Œä¼˜å…ˆåˆ¤æ–­ä¸ºè¯¦æƒ…æŸ¥è¯¢
            return 'detail', question
        
        # åˆ¤æ–­é—®é¢˜ç±»å‹
        if re.search(r'(æ€»ç»“|summary|summarize)', question_lower):
            return 'summary', question
        elif re.search(r'(è¶‹åŠ¿|trend|å‘å±•|evolution)', question_lower):
            return 'trend', question
        elif re.search(r'(å¯¹æ¯”|compare|comparison)', question_lower):
            return 'compare', question
        elif re.search(r'(è¯¦æƒ…|detail|information|info)', question_lower):
            return 'detail', question
        elif re.search(r'(æœç´¢|search|find|æŸ¥æ‰¾)', question_lower):
            return 'search', question
        else:
            # é»˜è®¤ä¸ºæœç´¢
            return 'search', question
    
    def extract_keywords(self, question):
        """
        ä»é—®é¢˜ä¸­æå–å…³é”®è¯
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        # ç®€å•çš„å…³é”®è¯æå–
        keywords = []
        
        # å¸¸è§å­¦æœ¯å…³é”®è¯
        academic_terms = [
            'machine learning', 'deep learning', 'neural network',
            'transformer', 'attention', 'gpt', 'bert', 'llm',
            'large language model', 'artificial intelligence', 'ai',
            'computer vision', 'nlp', 'natural language processing',
            'reinforcement learning', 'supervised learning',
            'unsupervised learning', 'clustering', 'classification'
        ]
        
        # å…ˆæŸ¥æ‰¾è‹±æ–‡æœ¯è¯­
        for term in academic_terms:
            if term.lower() in question.lower():
                keywords.append(term)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è‹±æ–‡æœ¯è¯­ï¼Œå°è¯•æå–ä¸­æ–‡å…³é”®è¯
        if not keywords and re.search(r'[\u4e00-\u9fff]', question):
            # æå–ä¸­æ–‡çŸ­è¯­
            chinese_phrases = re.findall(r'[\u4e00-\u9fff]{2,}', question)
            keywords.extend(chinese_phrases[:3])
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œå°è¯•æå–å¼•å·ä¸­çš„å†…å®¹
        if not keywords:
            quoted = re.findall(r'["\']([^"\']+)["\']', question)
            keywords.extend(quoted)
        
        return keywords
    
    def handle_search(self, question):
        """å¤„ç†æœç´¢é—®é¢˜"""
        keywords = self.extract_keywords(question)
        
        if not keywords:
            print("âŒ æ— æ³•ä»é—®é¢˜ä¸­æå–å…³é”®è¯ï¼Œè¯·æä¾›æ›´å…·ä½“çš„å…³é”®è¯")
            return
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªå…³é”®è¯æœç´¢
        keyword = keywords[0]
        
        # å°è¯•æå–å¹´ä»½
        year_match = re.search(r'(20\d{2})', question)
        start_year = int(year_match.group(1)) if year_match else None
        
        try:
            results = self.service.search_papers(
                keyword=keyword,
                start_year=start_year,
                page_size=5
            )
            
            print(f"\nğŸ” æœç´¢å…³é”®è¯: {keyword}")
            print(f"ğŸ“Š æ‰¾åˆ° {results['total']} ç¯‡è®ºæ–‡\n")
            
            for i, paper in enumerate(results['papers'], 1):
                authors = [a.get('name', 'Unknown') if isinstance(a, dict) else str(a) 
                          for a in paper.get('authors', [])[:3]]
                print(f"{i}. {paper['title']}")
                print(f"   ğŸ‘¤ ä½œè€…: {', '.join(authors)}")
                print(f"   ğŸ“… å¹´ä»½: {paper.get('publish_year', 'N/A')}")
                print(f"   ğŸ“š æœŸåˆŠ: {paper.get('journal', 'N/A')}")
                print(f"   ğŸ”— è¢«å¼•: {paper.get('citations', 0)}")
                print()
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
    
    def handle_detail(self, question):
        """å¤„ç†è¯¦æƒ…æŸ¥è¯¢"""
        # å°è¯•æå–è®ºæ–‡IDï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        id_match = re.search(r'W\d+', question)
        
        if id_match:
            paper_id = id_match.group(0)
        else:
            # å°è¯•ä»é—®é¢˜ä¸­æå–è®ºæ–‡æ ‡é¢˜
            keywords = self.extract_keywords(question)
            if keywords:
                # æœç´¢è®ºæ–‡
                results = self.service.search_papers(
                    keyword=keywords[0],
                    page_size=1
                )
                if results['papers']:
                    paper_id = results['papers'][0]['paper_id']
                else:
                    print("âŒ æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡")
                    return
            else:
                print("âŒ è¯·æä¾›è®ºæ–‡IDæˆ–è®ºæ–‡æ ‡é¢˜")
                return
        
        try:
            paper_info = self.service.get_paper_info(paper_id)
            
            if paper_info:
                print(f"\nğŸ“„ è®ºæ–‡è¯¦æƒ…\n")
                print(f"ğŸ“ æ ‡é¢˜: {paper_info.get('title', 'N/A')}")
                print(f"ğŸ“… å‘è¡¨å¹´ä»½: {paper_info.get('publish_year', 'N/A')}")
                print(f"ğŸ”— è¢«å¼•æ¬¡æ•°: {paper_info.get('citations', 0)}")
                print(f"ğŸ“š æœŸåˆŠ: {paper_info.get('journal', 'N/A')}")
                
                authors = [a.get('name', 'N/A') if isinstance(a, dict) else str(a) 
                          for a in paper_info.get('authors', [])[:5]]
                print(f"ğŸ‘¤ ä½œè€…: {', '.join(authors)}")
                
                keywords = paper_info.get('keywords', [])
                if keywords:
                    print(f"ğŸ·ï¸  å…³é”®è¯: {', '.join(keywords[:5])}")
                
                abstract = paper_info.get('abstract', '')
                if abstract:
                    print(f"\nğŸ“– æ‘˜è¦:\n{abstract[:500]}...")
            else:
                print("âŒ æœªæ‰¾åˆ°è¯¥è®ºæ–‡")
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
    
    def handle_summary(self, question):
        """å¤„ç†æ€»ç»“é—®é¢˜"""
        keywords = self.extract_keywords(question)
        
        if not keywords:
            print("âŒ æ— æ³•ä»é—®é¢˜ä¸­æå–å…³é”®è¯")
            return
        
        # æœç´¢ç›¸å…³è®ºæ–‡
        try:
            papers = self.service.search_papers(
                keyword=keywords[0],
                start_year=2023,
                page_size=3
            )
            
            if papers['papers']:
                print(f"\nğŸ” æ‰¾åˆ° {len(papers['papers'])} ç¯‡è®ºæ–‡ï¼Œæ­£åœ¨ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½æ€»ç»“...\n")
                
                # ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½æ€»ç»“
                result = self.llm_module.handle({
                    "type": "smart_summary",
                    "paper_ids": [p['paper_id'] for p in papers['papers']]
                })
                
                if result.get('code') == 200:
                    print(f"ğŸ“Š è®ºæ–‡æ•°é‡: {result['data'].get('papers_count', 0)}")
                    print(f"ğŸ¤– åˆ†ææ¨¡å‹: {result['data'].get('model', 'N/A')}")
                    print(f"\nğŸ“ æ™ºèƒ½æ€»ç»“:\n")
                    print(result['data'].get('summary', 'æš‚æ— æ€»ç»“'))
                else:
                    print(f"âŒ LLMåˆ†æå¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
            else:
                print("âŒ æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡")
        except Exception as e:
            print(f"âŒ æ€»ç»“å¤±è´¥: {e}")
    
    def handle_trend(self, question):
        """å¤„ç†è¶‹åŠ¿åˆ†æ"""
        keywords = self.extract_keywords(question)
        
        if not keywords:
            print("âŒ æ— æ³•ä»é—®é¢˜ä¸­æå–å…³é”®è¯")
            return
        
        try:
            print(f"\nğŸ” æ­£åœ¨æœç´¢ '{keywords[0]}' ç›¸å…³è®ºæ–‡å¹¶ä½¿ç”¨LLMåˆ†æè¶‹åŠ¿...\n")
            
            result = self.llm_module.handle({
                "type": "research_trend_analysis",
                "keyword": keywords[0],
                "start_year": 2022,
                "end_year": 2024
            })
            
            if result.get('code') == 200:
                print(f"ğŸ“Š åˆ†ææ—¶é—´èŒƒå›´: {result['data'].get('period', 'N/A')}")
                print(f"ğŸ“„ è®ºæ–‡æ•°é‡: {result['data'].get('papers_count', 0)}")
                print(f"ğŸ¤– åˆ†ææ¨¡å‹: {result['data'].get('model', 'N/A')}")
                print(f"\nğŸ“ˆ è¶‹åŠ¿åˆ†æ:\n")
                print(result['data'].get('trend_analysis', 'æš‚æ— åˆ†æ'))
            else:
                print(f"âŒ LLMåˆ†æå¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
        except Exception as e:
            print(f"âŒ è¶‹åŠ¿åˆ†æå¤±è´¥: {e}")
    
    def handle_compare(self, question):
        """å¤„ç†å¯¹æ¯”åˆ†æ"""
        keywords = self.extract_keywords(question)
        
        if len(keywords) < 2:
            print("âŒ å¯¹æ¯”åˆ†æéœ€è¦è‡³å°‘ä¸¤ä¸ªå…³é”®è¯")
            return
        
        try:
            # æœç´¢ç¬¬ä¸€ä¸ªå…³é”®è¯çš„è®ºæ–‡
            papers1 = self.service.search_papers(
                keyword=keywords[0],
                start_year=2023,
                page_size=2
            )
            
            # æœç´¢ç¬¬äºŒä¸ªå…³é”®è¯çš„è®ºæ–‡
            papers2 = self.service.search_papers(
                keyword=keywords[1],
                start_year=2023,
                page_size=2
            )
            
            all_papers = papers1['papers'] + papers2['papers']
            
            if all_papers:
                print(f"\nğŸ” æ‰¾åˆ° {len(all_papers)} ç¯‡è®ºæ–‡ï¼Œæ­£åœ¨ä½¿ç”¨LLMè¿›è¡Œå¯¹æ¯”åˆ†æ...\n")
                
                # ä½¿ç”¨LLMè¿›è¡Œå¯¹æ¯”åˆ†æ
                result = self.llm_module.handle({
                    "type": "paper_comparison",
                    "paper_ids": [p['paper_id'] for p in all_papers]
                })
                
                if result.get('code') == 200:
                    print(f"ğŸ“Š è®ºæ–‡æ•°é‡: {result['data'].get('papers_count', 0)}")
                    print(f"ğŸ¤– åˆ†ææ¨¡å‹: {result['data'].get('model', 'N/A')}")
                    print(f"\nğŸ“ å¯¹æ¯”åˆ†æ:\n")
                    print(result['data'].get('comparison', 'æš‚æ— åˆ†æ'))
                else:
                    print(f"âŒ LLMåˆ†æå¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
            else:
                print("âŒ æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡")
        except Exception as e:
            print(f"âŒ å¯¹æ¯”åˆ†æå¤±è´¥: {e}")
    
    def ask(self, question):
        """
        å¤„ç†ç”¨æˆ·é—®é¢˜
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
        """
        question_type, _ = self.understand_question(question)
        
        print(f"\n{'='*80}")
        print(f"â“ æ‚¨çš„é—®é¢˜: {question}")
        print(f"{'='*80}\n")
        
        # æ ¹æ®é—®é¢˜ç±»å‹è°ƒç”¨ç›¸åº”çš„å¤„ç†å‡½æ•°
        handlers = {
            'search': self.handle_search,
            'detail': self.handle_detail,
            'summary': self.handle_summary,
            'trend': self.handle_trend,
            'compare': self.handle_compare
        }
        
        handler = handlers.get(question_type, self.handle_search)
        handler(question)
    
    def run(self):
        """è¿è¡Œå¯¹è¯å¾ªç¯"""
        while True:
            try:
                question = input("\nğŸ’¬ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()
                
                if not question:
                    continue
                
                if question.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                    print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨å­¦æœ¯åŠ©æ‰‹ï¼Œå†è§ï¼")
                    break
                
                self.ask(question)
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨å­¦æœ¯åŠ©æ‰‹ï¼Œå†è§ï¼")
                break
            except Exception as e:
                print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•°"""
    assistant = AcademicChatAssistant()
    assistant.run()


if __name__ == "__main__":
    main()
