#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å­¦æœ¯Agentæµ‹è¯•è„šæœ¬ - ç”¨å­¦æœ¯é—®é¢˜æµ‹è¯•agentåŠŸèƒ½
"""

from academic_agent.services import LocalAcademicService
from academic_agent.llm import get_llm_adapter
from academic_agent.qa import LLMEnhancedResearchModule
from academic_agent.config import load_config


def test_academic_questions():
    """ç”¨å­¦æœ¯é—®é¢˜æµ‹è¯•agent"""
    
    # åŠ è½½é…ç½®
    config = load_config()
    llm_config = config.get("llm", {}).get("zhipu", {})
    
    # åˆå§‹åŒ–æœåŠ¡
    service = LocalAcademicService(adapter_name="openalex")
    
    # åˆå§‹åŒ–LLM
    llm_adapter = get_llm_adapter("zhipu", {
        "api_key": llm_config.get("api_key"),
        "model_name": llm_config.get("model", "qwen3-max"),
        "base_url": llm_config.get("base_url"),
        "temperature": llm_config.get("temperature", 0.7),
        "max_tokens": llm_config.get("max_tokens", 2000)
    })
    
    # åˆå§‹åŒ–LLMå¢å¼ºæ¨¡å—
    llm_module = LLMEnhancedResearchModule(
        adapter=service.adapter,
        llm_adapter=llm_adapter
    )
    
    print("=" * 80)
    print("å­¦æœ¯AgentåŠŸèƒ½æµ‹è¯•")
    print("=" * 80)
    
    # é—®é¢˜1: åŸºç¡€æŸ¥è¯¢ - æœç´¢æœºå™¨å­¦ä¹ é¢†åŸŸçš„æœ€æ–°è®ºæ–‡
    print("\n" + "=" * 80)
    print("é—®é¢˜1: 2024å¹´æœºå™¨å­¦ä¹ é¢†åŸŸæœ‰å“ªäº›é«˜è¢«å¼•è®ºæ–‡ï¼Ÿ")
    print("=" * 80)
    
    try:
        results = service.search_papers(
            keyword="machine learning",
            start_year=2024,
            page_size=5
        )
        
        print(f"\næ‰¾åˆ° {results['total']} ç¯‡è®ºæ–‡ï¼Œä»¥ä¸‹æ˜¯å‰5ç¯‡ï¼š\n")
        for i, paper in enumerate(results['papers'], 1):
            authors = [a.get('name', 'Unknown') if isinstance(a, dict) else str(a) 
                      for a in paper.get('authors', [])[:3]]
            print(f"{i}. {paper['title']}")
            print(f"   ä½œè€…: {', '.join(authors)}")
            print(f"   è¢«å¼•: {paper.get('citations', 0)}")
            print(f"   æœŸåˆŠ: {paper.get('journal', 'N/A')}")
            print(f"   å¹´ä»½: {paper.get('publish_year', 'N/A')}")
            print()
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
    
    # é—®é¢˜2: ä½œè€…åˆ†æ - æŸ¥è¯¢è‘—åAIç ”ç©¶è€…çš„è®ºæ–‡
    print("\n" + "=" * 80)
    print("é—®é¢˜2: Geoffrey Hintonæœ€è¿‘çš„ç ”ç©¶æ–¹å‘æ˜¯ä»€ä¹ˆï¼Ÿ")
    print("=" * 80)
    
    try:
        # å…ˆæœç´¢Geoffrey Hintonçš„è®ºæ–‡
        results = service.search_papers(
            keyword="Geoffrey Hinton",
            start_year=2020,
            page_size=3
        )
        
        print(f"\næ‰¾åˆ° {results['total']} ç¯‡ç›¸å…³è®ºæ–‡ï¼š\n")
        for i, paper in enumerate(results['papers'], 1):
            authors = [a.get('name', 'Unknown') if isinstance(a, dict) else str(a) 
                      for a in paper.get('authors', [])[:3]]
            print(f"{i}. {paper['title']}")
            print(f"   ä½œè€…: {', '.join(authors)}")
            print(f"   è¢«å¼•: {paper.get('citations', 0)}")
            print(f"   å¹´ä»½: {paper.get('publish_year', 'N/A')}")
            print()
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
    
    # é—®é¢˜3: ç»Ÿè®¡åˆ†æ - æ·±åº¦å­¦ä¹ é¢†åŸŸçš„å¹´åº¦å‘è¡¨è¶‹åŠ¿
    print("\n" + "=" * 80)
    print("é—®é¢˜3: æ·±åº¦å­¦ä¹ é¢†åŸŸè¿‘5å¹´çš„å‘è¡¨è¶‹åŠ¿å¦‚ä½•ï¼Ÿ")
    print("=" * 80)
    
    try:
        stats = service.get_keyword_yearly_stats(
            keyword="deep learning",
            start_year=2019,
            end_year=2023
        )
        
        print("\nå¹´åº¦å‘è¡¨ç»Ÿè®¡ï¼š\n")
        if stats.get('yearly_stats'):
            for year_stat in stats['yearly_stats']:
                print(f"  {year_stat.get('year', 'N/A')}: {year_stat.get('count', 0)} ç¯‡")
        else:
            print("  æš‚æ— ç»Ÿè®¡æ•°æ®")
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
    
    # é—®é¢˜4: LLMå¢å¼º - æ™ºèƒ½è®ºæ–‡æ€»ç»“
    print("\n" + "=" * 80)
    print("é—®é¢˜4: è¯·æ€»ç»“Transformerç›¸å…³çš„ç ”ç©¶è¿›å±•ï¼ˆä½¿ç”¨LLMåˆ†æï¼‰")
    print("=" * 80)
    
    try:
        # å…ˆæœç´¢Transformerç›¸å…³è®ºæ–‡
        papers = service.search_papers(
            keyword="transformer architecture",
            start_year=2022,
            page_size=3
        )
        
        if papers['papers']:
            # ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½æ€»ç»“
            result = llm_module.handle({
                "type": "smart_summary",
                "paper_ids": [p['paper_id'] for p in papers['papers']]
            })
            
            if result.get('code') == 200:
                print(f"\nğŸ“Š è®ºæ–‡æ•°é‡: {result['data'].get('papers_count', 0)}")
                print(f"ğŸ¤– åˆ†ææ¨¡å‹: {result['data'].get('model', 'N/A')}")
                print(f"\nğŸ“ æ™ºèƒ½æ€»ç»“:\n")
                print(result['data'].get('summary', 'æš‚æ— æ€»ç»“'))
            else:
                print(f"âŒ LLMåˆ†æå¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
        else:
            print("âŒ æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡")
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
    
    # é—®é¢˜5: LLMå¢å¼º - ç ”ç©¶è¶‹åŠ¿åˆ†æ
    print("\n" + "=" * 80)
    print("é—®é¢˜5: å¤§è¯­è¨€æ¨¡å‹é¢†åŸŸçš„ç ”ç©¶è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆä½¿ç”¨LLMåˆ†æï¼‰")
    print("=" * 80)
    
    try:
        result = llm_module.handle({
            "type": "research_trend_analysis",
            "keyword": "large language model",
            "start_year": 2022,
            "end_year": 2024
        })
        
        if result.get('code') == 200:
            print(f"\nğŸ“Š åˆ†ææ—¶é—´èŒƒå›´: {result['data'].get('period', 'N/A')}")
            print(f"ğŸ“„ è®ºæ–‡æ•°é‡: {result['data'].get('papers_count', 0)}")
            print(f"ğŸ¤– åˆ†ææ¨¡å‹: {result['data'].get('model', 'N/A')}")
            print(f"\nğŸ“ˆ è¶‹åŠ¿åˆ†æ:\n")
            print(result['data'].get('trend_analysis', 'æš‚æ— åˆ†æ'))
        else:
            print(f"âŒ LLMåˆ†æå¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
    
    # é—®é¢˜6: å…³è”åˆ†æ - è®ºæ–‡å¼•è¯å…³ç³»
    print("\n" + "=" * 80)
    print("é—®é¢˜6: Attention Is All You Needè¿™ç¯‡è®ºæ–‡çš„å¼•è¯å…³ç³»å¦‚ä½•ï¼Ÿ")
    print("=" * 80)
    
    try:
        # Attention Is All You Needçš„OpenAlex ID
        paper_id = "W2626778328"
        
        # è·å–è®ºæ–‡è¯¦æƒ…
        paper_info = service.get_paper_info(paper_id)
        if paper_info:
            print(f"\nè®ºæ–‡æ ‡é¢˜: {paper_info.get('title', 'N/A')}")
            print(f"å‘è¡¨å¹´ä»½: {paper_info.get('publish_year', 'N/A')}")
            print(f"è¢«å¼•æ¬¡æ•°: {paper_info.get('citations', 0)}")
            print(f"ä½œè€…: {', '.join([a.get('name', 'N/A') if isinstance(a, dict) else str(a) 
                                   for a in paper_info.get('authors', [])[:3]])}")
            print()
        
        # è·å–å¼•è¯å…³ç³»
        citation_data = service.get_citation_relations(paper_id, depth=1)
        
        print(f"å¼•ç”¨è¯¥è®ºæ–‡çš„æ•°é‡: {citation_data.get('citation_count', 0)}")
        print(f"\nå¼•ç”¨è¯¥è®ºæ–‡çš„å‰5ç¯‡è®ºæ–‡ï¼š\n")
        
        citing_papers = citation_data.get('citation_papers', [])[:5]
        for i, paper in enumerate(citing_papers, 1):
            authors = [a.get('name', 'Unknown') if isinstance(a, dict) else str(a) 
                      for a in paper.authors[:3]]
            print(f"{i}. {paper.title}")
            print(f"   ä½œè€…: {', '.join(authors)}")
            print(f"   è¢«å¼•: {paper.citations}")
            print()
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
    
    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆï¼")
    print("=" * 80)


if __name__ == "__main__":
    test_academic_questions()
